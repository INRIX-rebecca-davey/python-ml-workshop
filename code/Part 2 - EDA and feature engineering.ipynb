{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to import the libraries we're going to use\n",
    "# 'import x as y' will import package x but give it the alias 'y' so you don't have to type out x all the time\n",
    "\n",
    "import matplotlib.pyplot as plt # for making nice plots\n",
    "import pandas as pd # for handling and transforming the data\n",
    "import datetime # for manipulating dates, timestamps etc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll be using this file from now on! It's been through the process of cleaning and preparing\n",
    "df = pd.read_csv(\"../data/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference_num</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>num_vehicles</th>\n",
       "      <th>accident_date</th>\n",
       "      <th>accident_time</th>\n",
       "      <th>road_class</th>\n",
       "      <th>road_surface</th>\n",
       "      <th>lighting</th>\n",
       "      <th>weather</th>\n",
       "      <th>casualty_class</th>\n",
       "      <th>casualty_severity</th>\n",
       "      <th>casualty_sex</th>\n",
       "      <th>casualty_age</th>\n",
       "      <th>vehicle_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202609</td>\n",
       "      <td>53.891468</td>\n",
       "      <td>-1.667699</td>\n",
       "      <td>2</td>\n",
       "      <td>14-Mar-09</td>\n",
       "      <td>2330</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Darkness: no street lighting</td>\n",
       "      <td>Fine with high winds</td>\n",
       "      <td>Driver/Rider</td>\n",
       "      <td>Slight</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202609</td>\n",
       "      <td>53.891468</td>\n",
       "      <td>-1.667699</td>\n",
       "      <td>2</td>\n",
       "      <td>14-Mar-09</td>\n",
       "      <td>2330</td>\n",
       "      <td>Unclassified</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Darkness: no street lighting</td>\n",
       "      <td>Fine with high winds</td>\n",
       "      <td>Driver/Rider</td>\n",
       "      <td>Slight</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>810209</td>\n",
       "      <td>53.933915</td>\n",
       "      <td>-1.374070</td>\n",
       "      <td>1</td>\n",
       "      <td>03-Oct-09</td>\n",
       "      <td>630</td>\n",
       "      <td>A(M)</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Darkness: no street lighting</td>\n",
       "      <td>Fine with high winds</td>\n",
       "      <td>Driver/Rider</td>\n",
       "      <td>Slight</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>972109</td>\n",
       "      <td>53.911349</td>\n",
       "      <td>-1.384957</td>\n",
       "      <td>4</td>\n",
       "      <td>19-Nov-09</td>\n",
       "      <td>630</td>\n",
       "      <td>A(M)</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Darkness: no street lighting</td>\n",
       "      <td>Fine with high winds</td>\n",
       "      <td>Driver/Rider</td>\n",
       "      <td>Slight</td>\n",
       "      <td>Male</td>\n",
       "      <td>17</td>\n",
       "      <td>Car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>972109</td>\n",
       "      <td>53.911349</td>\n",
       "      <td>-1.384957</td>\n",
       "      <td>4</td>\n",
       "      <td>19-Nov-09</td>\n",
       "      <td>630</td>\n",
       "      <td>A(M)</td>\n",
       "      <td>Dry</td>\n",
       "      <td>Darkness: no street lighting</td>\n",
       "      <td>Fine with high winds</td>\n",
       "      <td>Driver/Rider</td>\n",
       "      <td>Slight</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>Goods vehicle 3.5 tonnes mgw and under</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reference_num   latitude  longitude  num_vehicles accident_date  \\\n",
       "0        202609  53.891468  -1.667699             2     14-Mar-09   \n",
       "1        202609  53.891468  -1.667699             2     14-Mar-09   \n",
       "2        810209  53.933915  -1.374070             1     03-Oct-09   \n",
       "3        972109  53.911349  -1.384957             4     19-Nov-09   \n",
       "4        972109  53.911349  -1.384957             4     19-Nov-09   \n",
       "\n",
       "   accident_time    road_class road_surface                      lighting  \\\n",
       "0           2330  Unclassified          Dry  Darkness: no street lighting   \n",
       "1           2330  Unclassified          Dry  Darkness: no street lighting   \n",
       "2            630          A(M)          Dry  Darkness: no street lighting   \n",
       "3            630          A(M)          Dry  Darkness: no street lighting   \n",
       "4            630          A(M)          Dry  Darkness: no street lighting   \n",
       "\n",
       "                weather casualty_class casualty_severity casualty_sex  \\\n",
       "0  Fine with high winds   Driver/Rider            Slight         Male   \n",
       "1  Fine with high winds   Driver/Rider            Slight       Female   \n",
       "2  Fine with high winds   Driver/Rider            Slight         Male   \n",
       "3  Fine with high winds   Driver/Rider            Slight         Male   \n",
       "4  Fine with high winds   Driver/Rider            Slight         Male   \n",
       "\n",
       "   casualty_age                            vehicle_type  \n",
       "0            30                                     Car  \n",
       "1            20                                     Car  \n",
       "2            29                                     Car  \n",
       "3            17                                     Car  \n",
       "4            53  Goods vehicle 3.5 tonnes mgw and under  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2a - removing unrelated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-ee5b2cc8d2ea>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-ee5b2cc8d2ea>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    useless_columns = ['reference_num', ???]\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# we know ahead of time that there are a few columns that definitely won't be useful for classification\n",
    "# at least not without extra information. One of these is the reference number. Any others?\n",
    "\n",
    "useless_columns = ['reference_num', ???]\n",
    "\n",
    "df = df.drop(columns=useless_columns)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a range of different columns left\n",
    "# some are numerical, some are date/time-related, some are categorical, and some are binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2b - exploring binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of our columns are binary, in that they only ever have one of two values. \n",
    "# what are these columns?\n",
    "binary_columns = [???]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "casualty_severity  casualty_sex\n",
       "Serious            Female           655\n",
       "                   Male            1537\n",
       "Slight             Female          7038\n",
       "                   Male            9653\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at one of these binary column - casualty sex. Does it matter? What can we tell from this data?\n",
    "\n",
    "df.groupby(['casualty_severity', 'casualty_sex']).size()\n",
    "\n",
    "# hint: men are the casualty in 58% of slight accidents but 70% of serious accidents\n",
    "# this could be useful information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as our columns are binary we can encode them using 0 and 1 instead of string labels - much easier to handle later!\n",
    "\n",
    "# write a function will return 1 if our value matches the specified 'positive' value\n",
    "# e.g. encodeBinary('Male', 'Female') = 0, encodeBinary('Serious', 'Serious') = 1\n",
    "def encode_binary(positive_value, our_value):\n",
    "    ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now apply this function to get new binary columns\n",
    "df['is_male'] = [encode_binary('Male', s) for s in df.casualty_sex]\n",
    "df['is_serious'] = [encode_binary('Serious', s) for s in df.casualty_severity]\n",
    "\n",
    "# we can drop the old columns, now we have the binary versions\n",
    "df = df.drop(columns = binary_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2c - exploring numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical columns - are they useful? Do we want to do anything with them?\n",
    "\n",
    "# these are the numerical columns in our dataset\n",
    "# choose one and have a look at the distribution of values\n",
    "# extra points: break these down by slight/serious\n",
    "numericalColumns = ['num_vehicles', 'casualty_age']\n",
    "\n",
    "???\n",
    "\n",
    "# hint: plt.hist(values) will give a histogram of a list of values\n",
    "# hint: df.groupby(['columnsToGroupBy'])['otherColumnsToMeasureAgainst'].agg(['count', 'sum', etc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case, these columns are fine as they are and we don't want to normalise or modify them, so let's carry on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2d - exploring datetime columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-5032d4e8769c>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-5032d4e8769c>\"\u001b[1;36m, line \u001b[1;32m15\u001b[0m\n\u001b[1;33m    df['month'] = ???\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# in their current format, fields like accident_date aren't very useful - we want to extract useful columns\n",
    "\n",
    "monthMap = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, \n",
    "            'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "# write a function to take a date string of format DD-Mon-YY and extract the month as an integer\n",
    "def getMonth(s):\n",
    "    ???\n",
    "\n",
    "# write a function to take a date string of format DD-Mon-YY and extract the full year as an integer\n",
    "def getYear(s):\n",
    "    ???\n",
    "\n",
    "# use these functions to add new columns to our dataframe\n",
    "df['month'] = ???\n",
    "df['year'] = ???\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-77aa9eb60c53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# does the year matter? let's have a look at the distribution of slight vs serious cases by year\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mallByYear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mslightByYear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_serious\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mallByYear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m   5160\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   5161\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5162\u001b[1;33m                        **kwargs)\n\u001b[0m\u001b[0;32m   5163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5164\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, mutated, validate)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2934\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2935\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'year'"
     ]
    }
   ],
   "source": [
    "# but does the year matter? let's have a look at the trends by year\n",
    "\n",
    "allByYear = df.groupby('year')['year'].count()\n",
    "slightByYear = df[df.is_serious == 0].groupby('year')['year'].count()\n",
    "allByYear.plot()\n",
    "slightByYear.plot()\n",
    "\n",
    "# answer: year is probably not a good indicator of slight/serious, same for month, so let's drop these\n",
    "\n",
    "df = df.drop(columns=['year', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about weekday? we can get this information!\n",
    "\n",
    "day_map = {1: 'Mon', 2: 'Tue', 3: 'Wed', 4: 'Thu', 5: 'Fri', 6: 'Sat', 7: 'Sun'}\n",
    "\n",
    "def get_weekday(s):\n",
    "    month = ???\n",
    "    year = ???\n",
    "    date = ???\n",
    "    dt = datetime.datetime(year, month, date)\n",
    "    return day_map[dt.isoweekday()]\n",
    "\n",
    "df['weekday'] = [get_weekday(s) for s in df['accident_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'weekday'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-31c6e6074c13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mday_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Mon'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Tue'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Wed'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Thu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fri'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sun'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mallByDay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'weekday'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weekday'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mallByDay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mday_order\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m   5160\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[0;32m   5161\u001b[0m                        \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5162\u001b[1;33m                        **kwargs)\n\u001b[0m\u001b[0;32m   5163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5164\u001b[0m     def asfreq(self, freq, method=None, how=None, normalize=False,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36mgroupby\u001b[1;34m(obj, by, **kwds)\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid type: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m                                                     mutated=self.mutated)\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\mlworkshop\\lib\\site-packages\\pandas\\core\\groupby.py\u001b[0m in \u001b[0;36m_get_grouper\u001b[1;34m(obj, key, axis, level, sort, mutated, validate)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2934\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2935\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m             \u001b[1;31m# Add key to exclusions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'weekday'"
     ]
    }
   ],
   "source": [
    "# let's look at accident casualties by day of the week!\n",
    "\n",
    "day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "grouped_by_day = df.groupby(???)[???].agg([???])\n",
    "\n",
    "grouped_by_day.loc[day_order].plot()\n",
    "\n",
    "# this looks interesting, so let's keep weekday as a feature for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that's enough datetime business - let's tidy up drop the original columns and carry on\n",
    "df = df.drop(columns = ['accident_date', 'accident_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2e - exploring categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which of our columns are categorical? I've started off with 'road_class'\n",
    "categorical_columns = ['road_class', ???]\n",
    "\n",
    "# let's have a look at the values we have for these categories\n",
    "for cat_col in categorical_columns:\n",
    "    countByRoadClass = df.groupby(cat_col)[cat_col].agg(['count'])\n",
    "    countByRoadClass.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at road surface - the distribution is quite imbalanced\n",
    "# we're going to try reducing this to a binary column, where it's either dry or not\n",
    "\n",
    "df['is_dry'] = [??? for s in df.road_surface]\n",
    "\n",
    "df = df.drop(columns = ['road_surface'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to use one-hot encoding to translate the other categorical columns from text labels into separate binary columns\n",
    "# we can build this up in a modular way\n",
    "\n",
    "# first let's have a function with two arguments, that returns 1 if they're the same and 0 if they're not\n",
    "# hint: where have we encountered this before?\n",
    "def one_hot_encode_value(value, target):\n",
    "    ???\n",
    "    \n",
    "# this function takes a category and option and turns it into a new column name\n",
    "# e.g. in the road class category, the label 'A' becomes a new column 'road_class_is_A'\n",
    "def make_column_name(category_name, field_name):\n",
    "    return category_name + '_is_' + field_name.lower().replace(' ','_')\n",
    "\n",
    "# this function applies one-hot-encoding to a whole column\n",
    "# it's a bit involved but have a read through and see if you can see what it's doing\n",
    "def one_hot_encode_column(df, category_name, category_options):\n",
    "    for option in category_options:\n",
    "        new_column = make_column_name(category_name, option)\n",
    "        df[new_column] = [one_hot_encode_value(s, option) for s in df[category_name]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to one-hot encode lots of things! Let's start with vehicle type...\n",
    "# but before we do one-hot encoding, let's reduce the number of options here\n",
    "\n",
    "# this function will take a vehicle type and reduce it to one of four options (instead of lots)\n",
    "def encode_vehicle_as_string(s):\n",
    "    if s == 'Car':\n",
    "        return s\n",
    "    elif s == 'Pedal cycle':\n",
    "        return s\n",
    "    elif s == 'Bus or coach (17 or more passenger seats)':\n",
    "        return 'Bus or coach'\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "df['vehicle_type_reduced'] = [encode_vehicle_as_string(s) for s in df.vehicle_type]\n",
    "\n",
    "# use the one-hot encoding to return a new dataframe with vehicle_type_reduced encoded\n",
    "df = one_hot_encode_column(???, ???, ???)\n",
    "\n",
    "df = df.drop(columns = ['vehicle_type', 'vehicle_type_reduced'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's one hot encode lighting\n",
    "\n",
    "df = one_hot_encode_column(df, 'lighting', set(df.lighting.values))\n",
    "df = df.drop(columns = ['lighting'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and casualty class and weekday from earlier!\n",
    "\n",
    "df = ???\n",
    "df = ???\n",
    "\n",
    "df = df.drop(columns=['casualty_class', 'weekday'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-6fb0a1a0889f>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-20-6fb0a1a0889f>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    severity_by_weather = ???\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# finally, let's look at weather a bit more carefully\n",
    "# there are quite a lot of options - maybe we could simplify this a bit?\n",
    "\n",
    "# let's try to group by weather and severity\n",
    "severity_by_weather = ???\n",
    "\n",
    "# what are all the possible options that weather can take?\n",
    "weather_options = ???\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "# here we're going to iterate through the options and use our grouped data to count serious vs slight\n",
    "# we'll measure the proportion between the two and plot it!\n",
    "for weather_type in weather_options:\n",
    "    subDf = severity_by_weather.loc[weather_type]\n",
    "    slight_count = subDf.iloc[0]['count']\n",
    "    serious_count = subDf.iloc[1]['count']\n",
    "    \n",
    "    x.append(???)\n",
    "    y.append(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-19aecc738bdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# let's plot this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Serious/slight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# let's plot this\n",
    "plt.bar(x,y)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Serious/slight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quite a lot of variation, not really tied to fine/raining or high winds\n",
    "# so let's hot encode the lot and move on to the exciting stuff.\n",
    "\n",
    "df = one_hot_encode_column(df, 'weather', set(df.weather.values))\n",
    "df = df.drop(columns=['weather'])\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
